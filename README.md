# Dataset Processing Pipeline - Financial Behavior Risk Analysis

## ğŸ“‹ Project Overview

This project implements a comprehensive data processing and analysis pipeline for **financial behavior risk assessment**. The system processes survey data about financial habits, spending patterns, and economic behaviors to predict and analyze financial risk levels.

### Key Features
- **Data Preprocessing & Normalization** - Translation, encoding, and feature engineering
- **Advanced Exploratory Data Analysis (EDA)** - Statistical analysis with multiple visualization techniques
- **Dimensionality Reduction** - PCA analysis for feature extraction
- **Clustering Analysis** - K-Means and GMM clustering for behavioral segmentation
- **Reproducible Experiments** - Single entrypoint with YAML configs for consistent results
- **Synthetic Data Quality Gates** - Rigorous validation before using any synthetic data
- **Comprehensive Test Suite** - Pytest-based tests for reproducibility verification

---

## âš ï¸ CRITICAL: Clean Baseline Rules (NON-NEGOTIABLE)

### Forbidden Targets
**`Behavior_Risk_Level` is FORBIDDEN as a training target** - This is a circular label derived from features.

### Allowed Targets (LOCKED)
| Target | Type | Use Case |
|--------|------|----------|
| `Risk_Score` | Continuous | **Primary** - Regression |
| `Save_Money_Yes` | Binary | **Secondary** - Classification |

### Hard Removals (FOREVER)
- Retrain loops on enriched data
- Exponential dataset growth
- Final 50/50 balancing
- GAN retraining on synthetic output

---

## ğŸš€ Quick Start

### Installation

```bash
# Install dependencies
pip install -r requirements.txt

# Or minimal dependencies
pip install -r requirements_minimal.txt
```

### Run Clean Baselines

```bash
# Run regression baseline (Risk_Score target) - PRIMARY
python run_experiment.py --config configs/baseline_regression.yaml --dataset path/to/data.csv

# Run classification baseline (Save_Money target) - SECONDARY
python run_experiment.py --config configs/baseline_classification.yaml --dataset path/to/data.csv

# Run ALL baselines at once
python run_experiment.py --all-baselines --dataset path/to/data.csv
```

### Run Augmentation Experiment (Tests if synthetic helps)

```bash
# Test whether synthetic data improves real-only performance
python augmentation_experiment.py --config configs/augmentation_experiment.yaml --dataset path/to/data.csv
```

### Run Tests

```bash
# Install test dependencies
pip install pytest pytest-cov

# Run all tests
pytest -v

# Run with coverage
pytest --cov=. --cov-report=html
```

---

## ğŸ“Š Output per Run

Each experiment run produces a folder in `runs/` containing:

| File | Description |
|------|-------------|
| `config.yaml` | Experiment configuration used |
| `metrics.json` | All CV metrics (mean Â± std) |
| `model.joblib` | Trained model (sklearn format) |
| `cv_distribution.png` | Cross-validation score distribution |

### Validation Protocol
- **Repeated K-Fold CV:** 5 folds Ã— 10 repeats = 50 evaluations
- **Regression metrics:** MAE, RMSE, Spearman correlation, RÂ²
- **Classification metrics:** Macro-F1, Accuracy, Precision, Recall

---

## ğŸ—‚ï¸ Project Structure

```
Procesare Dataset/
â”œâ”€â”€ run_experiment.py              # MAIN ENTRYPOINT - reproducible experiments
â”œâ”€â”€ augmentation_experiment.py     # Controlled synthetic augmentation testing
â”œâ”€â”€ pytest.ini                     # Pytest configuration
â”‚
â”œâ”€â”€ configs/                       # Experiment configurations (YAML)
â”‚   â”œâ”€â”€ baseline_regression.yaml         # Risk_Score regression (PRIMARY)
â”‚   â”œâ”€â”€ baseline_classification.yaml     # Save_Money classification (SECONDARY)
â”‚   â”œâ”€â”€ augmentation_experiment.yaml     # Synthetic augmentation testing
â”‚   â”œâ”€â”€ default.yaml                     # Default config template
â”‚   â””â”€â”€ smote_experiment.yaml            # SMOTE augmentation config
â”‚
â”œâ”€â”€ tests/                         # Test suite (pytest)
â”‚   â”œâ”€â”€ conftest.py                      # Fixtures and test utilities
â”‚   â”œâ”€â”€ test_config.py                   # Config validation tests
â”‚   â”œâ”€â”€ test_data_integrity.py           # Data preprocessing tests
â”‚   â”œâ”€â”€ test_cv_and_leakage.py           # CV and leakage detection tests
â”‚   â”œâ”€â”€ test_augmentation_policy.py      # Augmentation policy tests
â”‚   â”œâ”€â”€ test_reproducibility.py          # Reproducibility verification
â”‚   â””â”€â”€ test_artifacts.py                # Output artifact tests
â”‚
â”œâ”€â”€ runs/                          # Output folder for experiment runs
â”‚
â”œâ”€â”€ FirstProcessing/               # Initial data processing pipeline
â”‚   â”œâ”€â”€ main.py                          # Entry point for preprocessing
â”‚   â”œâ”€â”€ preprocessing.py                 # Data normalization (ROâ†’EN translation)
â”‚   â”œâ”€â”€ risk_calculation.py              # Risk scoring and clustering
â”‚   â”œâ”€â”€ encoder.py                       # Feature encoding utilities
â”‚   â”œâ”€â”€ data_generation.py               # Feature engineering
â”‚   â””â”€â”€ file_operations.py               # File I/O and Excel formatting
â”‚
â”œâ”€â”€ EDA/                           # Exploratory Data Analysis
â”‚   â”œâ”€â”€ V1/                              # Basic EDA (legacy)
â”‚   â”‚   â”œâ”€â”€ mainEDA.py
â”‚   â”‚   â”œâ”€â”€ data_loading.py
â”‚   â”‚   â”œâ”€â”€ preprocessing.py
â”‚   â”‚   â”œâ”€â”€ visualization.py
â”‚   â”‚   â””â”€â”€ model_training.py
â”‚   â”‚
â”‚   â””â”€â”€ V2/                              # Advanced EDA (CURRENT)
â”‚       â”œâ”€â”€ mainEDA2.py                  # Main workflow with PCA + clustering
â”‚       â”œâ”€â”€ config.py                    # Configuration settings
â”‚       â”œâ”€â”€ data_loader.py               # Data loading and preparation
â”‚       â”œâ”€â”€ plot_generator.py            # Comprehensive plotting
â”‚       â”œâ”€â”€ utils.py                     # Utility functions
â”‚       â”œâ”€â”€ PCA/                         # Principal Component Analysis
â”‚       â”‚   â”œâ”€â”€ pca_transformer.py
â”‚       â”‚   â””â”€â”€ pca_visualizer.py
â”‚       â””â”€â”€ clustering/                  # Clustering analysis
â”‚           â”œâ”€â”€ kmeans_clustering.py
â”‚           â”œâ”€â”€ gmm_clustering.py
â”‚           â”œâ”€â”€ cluster_comparison.py
â”‚           â””â”€â”€ cluster_visualizer.py
â”‚
â”œâ”€â”€ DataAugmentation/              # Synthetic data generation
â”‚   â”œâ”€â”€ __init__.py                      # Module exports
â”‚   â”œâ”€â”€ base.py                          # Base augmentation class
â”‚   â”œâ”€â”€ quality_gates.py                 # Synthetic data quality gates
â”‚   â”œâ”€â”€ cluster_enrichment.py            # Cluster-aware enrichment
â”‚   â”œâ”€â”€ smote_tomek.py                   # SMOTE-Tomek (DEPRECATED)
â”‚   â”œâ”€â”€ CTGan_Augmentation.py            # CTGAN augmentation
â”‚   â””â”€â”€ WC_GAN.py                        # Wasserstein GAN
â”‚
â”œâ”€â”€ Old/                           # Deprecated experiments (DO NOT USE)
â”‚
â”œâ”€â”€ scaler/                        # Saved preprocessing models
â”‚   â””â”€â”€ robust_scaler.pkl
â”‚
â”œâ”€â”€ requirements.txt               # Full Python dependencies
â””â”€â”€ requirements_minimal.txt       # Minimal dependencies
```

---

## ğŸ”¬ Synthetic Data Quality Gates (Sprint 2)

Before any synthetic data is used, it must pass **ALL** quality gates:

### Gate 1: Memorization Test
Synthetic samples must not be near-duplicates of real samples.

### Gate 2: Two-Sample Test
A classifier trying to distinguish real vs synthetic must have AUC < 0.75.

### Gate 3: Utility Test
Training on real+synthetic must improve (or not hurt) real-only test performance.

### Gate 4: Stability Test
Variance across CV folds must not increase by more than 20%.

### Quality Gates Logic
```
For each CV fold:
  1. Generate synthetic data INSIDE the fold
  2. Run all 4 quality gates
  3. If ALL gates pass â†’ use augmented training data
  4. If ANY gate fails â†’ use real-only training data
  
Final verdict:
  - "useful" if improvement > 1% AND stability not degraded
  - "not_useful" otherwise (this is valid science!)
```

### Synthetic Ratio Limits
- Minimum: 15%
- Maximum: 30%
- **Never** exceed these bounds

---

## ğŸ“‹ Workflow

### Step 1: Data Preprocessing

```bash
python -m FirstProcessing.main
```

**Purpose:** Transform raw survey data into ML-ready format

**What it does:**
- Translation: Romanian â†’ English
- Normalization: Standardize categorical values
- Feature Engineering: Age grouping, income categorization, product lifetime
- Risk Calculation: Weighted scoring (15+ features), GMM clustering, outlier detection

**Output:** `encoded_data.csv` / `encoded_data.xlsx`

---

### Step 2: Exploratory Data Analysis

```bash
python -m EDA.V2.mainEDA2
```

**Features:**
- Univariate/Bivariate analysis
- Correlation heatmaps
- PCA (80% variance threshold)
- K-Means and GMM clustering
- Cluster comparison metrics

**Configuration** (`EDA/V2/config.py`):
```python
PCA_VARIANCE_THRESHOLD = 0.80
CLUSTERING_K_RANGE = (2, 11)
TARGET = "Risk_Score"
DPI = 300
```

---

### Step 3: Run Baseline Experiments

```bash
# Primary target: Risk_Score (regression)
python run_experiment.py --config configs/baseline_regression.yaml --dataset data.csv

# Secondary target: Save_Money_Yes (classification)
python run_experiment.py --config configs/baseline_classification.yaml --dataset data.csv
```

**Models Available:**

| Regression | Classification |
|------------|----------------|
| Ridge | Logistic Regression |
| Lasso | Random Forest |
| XGBoost Regressor | XGBoost Classifier |
| LightGBM Regressor | LightGBM Classifier |
| Random Forest Regressor | |

---

### Step 4: Test Synthetic Augmentation (Optional)

```bash
python augmentation_experiment.py --config configs/augmentation_experiment.yaml --dataset data.csv
```

**Methods available:**
- `jitter` - Gaussian noise injection (default for regression)
- `smote` - SMOTE oversampling (for classification)
- `cluster` - Cluster-aware enrichment (max 20% per cluster)

**Output:**
- Verdict: "useful" or "not_useful"
- Comparison metrics: real-only vs augmented
- Quality gate results per fold

---

## ğŸ§ª Test Suite

The project includes a comprehensive test suite:

| Test File | Purpose |
|-----------|---------|
| `test_config.py` | Validates forbidden target blocking, config hashing |
| `test_data_integrity.py` | Ensures proper feature/target separation |
| `test_cv_and_leakage.py` | Verifies CV returns expected metrics |
| `test_augmentation_policy.py` | Confirms baseline forces augmentation OFF |
| `test_reproducibility.py` | Same seed = same results |
| `test_artifacts.py` | Checks all output files are created |

```bash
# Run all tests
pytest -v

# Run specific test file
pytest tests/test_reproducibility.py -v

# Run with coverage report
pytest --cov=. --cov-report=term-missing
```

---

## ğŸ“ Data Format

### Input (Raw Survey)
- Format: CSV/Excel (Romanian language)
- ~22 survey questions covering demographics, financial behaviors, savings, etc.

### Processed (Encoded)
- Format: CSV/Excel (English, encoded)
- 80+ one-hot encoded features
- Target variables:
  - `Risk_Score` (continuous) - **USE THIS**
  - `Behavior_Risk_Level` (binary) - **FORBIDDEN AS TARGET**
- Metadata: `Confidence`, `Cluster`, `Outlier`

---

## âš™ï¸ Configuration Reference

### `configs/baseline_regression.yaml`
```yaml
experiment:
  name: "clean_baseline_regression"
  seed: 42

data:
  target_column: "Risk_Score"
  target_type: "regression"

preprocessing:
  ignored_columns: ["Behavior_Risk_Level"]

augmentation:
  enabled: false  # OFF for baseline

cross_validation:
  n_splits: 5
  n_repeats: 10
```

### `configs/augmentation_experiment.yaml`
```yaml
augmentation:
  enabled: true
  synthetic_ratio: 0.15  # 15%
  max_ratio: 0.30        # Never exceed 30%
  method: "jitter"       # jitter, smote, or cluster

quality_gates:
  memorization_threshold: 0.05
  max_discriminator_auc: 0.75
```

---

## ğŸ“š Dependencies

**Core:**
- pandas, numpy, scipy
- scikit-learn, xgboost, lightgbm
- imbalanced-learn (SMOTE)
- pyyaml, joblib

**Visualization:**
- matplotlib, seaborn

**Testing:**
- pytest, pytest-cov

**Optional (GANs):**
- torch, sdv (CTGAN)

See `requirements.txt` for complete list.

---

## ğŸ“ Changelog

### Sprint 2 (January 2026) - Controlled Synthetic Augmentation
- Added `DataAugmentation/quality_gates.py` - 4 mandatory quality gates
- Added `DataAugmentation/cluster_enrichment.py` - Cluster-aware generation
- Added `augmentation_experiment.py` - Controlled augmentation testing
- Added `tests/` - Comprehensive pytest suite
- Added `pytest.ini` - Test configuration
- Fixed Ridge/Lasso random_state compatibility
- Updated all configs to use Risk_Score (not Behavior_Risk_Level)

### Sprint 1 (January 2026) - Clean Baselines
- Created `run_experiment.py` - Single reproducible entrypoint
- Added FORBIDDEN_TARGETS blocking
- Implemented Repeated K-Fold CV (5Ã—10)
- Created baseline configs for regression and classification

---

## âš ï¸ Known Limitations

- **Old folder:** Contains deprecated experiments - DO NOT USE
- **CPU-Only:** GANs configured for CPU (`cuda=False`)
- **Language:** Raw survey data must be in Romanian for FirstProcessing

---

## ğŸ¯ Scientific Validity

This project follows strict reproducibility principles:

1. **Deterministic seeds** - numpy/sklearn/torch seeded everywhere
2. **No circular labels** - Behavior_Risk_Level forbidden as target
3. **Quality gates** - Synthetic data must prove utility before use
4. **Repeated CV** - 50 evaluations (5 folds Ã— 10 repeats) for stable metrics
5. **Test coverage** - Automated tests verify reproducibility

**Important:** If synthetic augmentation does not help, that result is reported as "not_useful" - this is **valid science**, not a failure.

